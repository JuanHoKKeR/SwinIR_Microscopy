#!/usr/bin/env python3
"""
Evaluador de Validaci√≥n para Modelo SwinIR Optimizado (.pt)
Eval√∫a modelos optimizados con su dataset de validaci√≥n correspondiente
Genera CSVs con m√©tricas en color y blanco y negro
KimiaNet es opcional para evitar problemas de memoria
"""

import os
import argparse
import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from pathlib import Path
import time
from tqdm import tqdm
import warnings
import cv2
from collections import OrderedDict

# Imports para utilidades de imagen
from utils import utils_image as util

# Imports para KimiaNet (opcional)
try:
    import tensorflow as tf
    from tensorflow.keras.applications import DenseNet121
    KIMIANET_AVAILABLE = True
except ImportError:
    KIMIANET_AVAILABLE = False
    print("‚ö†Ô∏è  TensorFlow no disponible - KimiaNet deshabilitado")

warnings.filterwarnings('ignore')

class OptimizedSwinIRModelEvaluator:
    """Evaluador para modelos SwinIR optimizados (.pt)"""
    
    def __init__(self, use_kimianet=True, kimianet_weights_path=None):
        """
        Inicializa el evaluador
        
        Args:
            use_kimianet: Si usar KimiaNet para √≠ndice perceptual
            kimianet_weights_path: Ruta a los pesos de KimiaNet (opcional)
        """
        self.use_kimianet = use_kimianet and KIMIANET_AVAILABLE
        self.kimianet_weights_path = kimianet_weights_path
        self.model = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.feature_extractor = None
        
        if self.use_kimianet and kimianet_weights_path:
            self._initialize_kimianet()
        else:
            print("üìä Evaluaci√≥n sin KimiaNet - solo m√©tricas b√°sicas")
    
    def _initialize_kimianet(self):
        """Inicializa DenseNet121 con pesos KimiaNet para √≠ndice perceptual"""
        if not KIMIANET_AVAILABLE:
            print("‚ùå TensorFlow no disponible - KimiaNet deshabilitado")
            self.use_kimianet = False
            return
            
        print("üß† Inicializando KimiaNet para √≠ndice perceptual...")
        
        try:
            self.densenet = DenseNet121(
                include_top=False, 
                weights=None,
                input_shape=(None, None, 3)
            )
            
            if os.path.exists(self.kimianet_weights_path):
                try:
                    self.densenet.load_weights(self.kimianet_weights_path)
                    print(f"‚úÖ Pesos KimiaNet cargados desde: {self.kimianet_weights_path}")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Error cargando pesos KimiaNet: {e}")
                    print("    Continuando sin KimiaNet")
                    self.use_kimianet = False
                    return
            else:
                print(f"‚ö†Ô∏è  No se encontr√≥ el archivo de pesos: {self.kimianet_weights_path}")
                self.use_kimianet = False
                return
            
            # Usar capa intermedia para caracter√≠sticas
            try:
                feature_layer = self.densenet.get_layer('conv4_block6_concat')
            except:
                try:
                    feature_layer = self.densenet.get_layer('conv4_block24_concat')
                except:
                    feature_layer = self.densenet.layers[-2]
            
            self.feature_extractor = tf.keras.Model(
                inputs=self.densenet.input,
                outputs=feature_layer.output
            )
            
            for layer in self.feature_extractor.layers:
                layer.trainable = False
                
            print(f"‚úÖ Extractor de caracter√≠sticas listo: {feature_layer.name}")
            
        except Exception as e:
            print(f"‚ùå Error inicializando KimiaNet: {e}")
            self.use_kimianet = False
    
    def load_optimized_model(self, model_path):
        """
        Carga el modelo SwinIR optimizado (.pt)
        
        Args:
            model_path: Ruta al archivo .pt del modelo optimizado
        """
        print(f"üì¶ Cargando modelo SwinIR optimizado desde: {model_path}")
        
        try:
            # Cargar modelo optimizado directamente
            self.model = torch.load(model_path, map_location=self.device)
            self.model.eval()
            
            print("‚úÖ Modelo SwinIR optimizado cargado correctamente")
            
            # Verificar que funciona con una imagen de prueba
            test_input = torch.randn(1, 3, 64, 64).to(self.device)
            with torch.no_grad():
                test_output = self.model(test_input)
            print(f"üß™ Prueba de inferencia exitosa - Input: {test_input.shape}, Output: {test_output.shape}")
            
        except Exception as e:
            print(f"‚ùå Error cargando modelo optimizado: {e}")
            raise
    
    def load_validation_dataset(self, lr_meta_file, hr_meta_file, base_path=""):
        """
        Carga el dataset de validaci√≥n desde archivos paired_meta
        
        Args:
            lr_meta_file: Archivo con rutas de im√°genes LR
            hr_meta_file: Archivo con rutas de im√°genes HR  
            base_path: Ruta base para las im√°genes
            
        Returns:
            Lista de tuplas (lr_path, hr_path)
        """
        print(f"üìÇ Cargando dataset de validaci√≥n...")
        print(f"   LR meta: {lr_meta_file}")
        print(f"   HR meta: {hr_meta_file}")
        
        # Cargar rutas LR
        with open(lr_meta_file, 'r') as f:
            lr_paths = [os.path.join(base_path, line.strip()) for line in f if line.strip()]
        
        # Cargar rutas HR
        with open(hr_meta_file, 'r') as f:
            hr_paths = [os.path.join(base_path, line.strip()) for line in f if line.strip()]
        
        print(f"‚úÖ Cargadas {len(lr_paths)} im√°genes LR y {len(hr_paths)} im√°genes HR")
        
        # Verificar que las cantidades coinciden
        if len(lr_paths) != len(hr_paths):
            print(f"‚ö†Ô∏è  Advertencia: N√∫mero diferente de im√°genes LR ({len(lr_paths)}) y HR ({len(hr_paths)})")
        
        # Verificar que existen algunas im√°genes de muestra
        sample_size = min(5, len(lr_paths))
        missing_files = 0
        for i in range(sample_size):
            if not os.path.exists(lr_paths[i]):
                missing_files += 1
                print(f"‚ö†Ô∏è  Archivo LR no encontrado: {lr_paths[i]}")
            if not os.path.exists(hr_paths[i]):
                missing_files += 1
                print(f"‚ö†Ô∏è  Archivo HR no encontrado: {hr_paths[i]}")
        
        if missing_files > 0:
            print(f"‚ö†Ô∏è  Se encontraron {missing_files} archivos faltantes en la muestra")
        
        # Crear pares de rutas
        image_pairs = list(zip(lr_paths, hr_paths))
        print(f"üìä Dataset preparado con {len(image_pairs)} pares de im√°genes")
        
        return image_pairs
    
    def load_image(self, image_path):
        """Carga una imagen usando OpenCV y la convierte a tensor PyTorch"""
        try:
            # Cargar imagen con OpenCV (BGR)
            image = cv2.imread(image_path, cv2.IMREAD_COLOR)
            if image is None:
                return None
            
            # Convertir BGR a RGB
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # Convertir a float32 y normalizar a [0, 1]
            image = image.astype(np.float32) / 255.0
            
            # Convertir a tensor PyTorch y cambiar dimensiones a CHW
            image_tensor = torch.from_numpy(image).permute(2, 0, 1)
            
            return image_tensor
        except Exception as e:
            print(f"‚ùå Error cargando imagen {image_path}: {e}")
            return None
    
    def convert_to_grayscale_torch(self, image_tensor):
        """Convierte tensor PyTorch RGB a escala de grises"""
        try:
            # Conversi√≥n usando pesos est√°ndar RGB a grayscale
            if len(image_tensor.shape) == 4:  # NCHW
                r, g, b = image_tensor[:, 0:1, :, :], image_tensor[:, 1:2, :, :], image_tensor[:, 2:3, :, :]
            else:  # CHW
                r, g, b = image_tensor[0:1, :, :], image_tensor[1:2, :, :], image_tensor[2:3, :, :]
            
            grayscale = 0.299 * r + 0.587 * g + 0.114 * b
            
            # Convertir de vuelta a 3 canales
            if len(image_tensor.shape) == 4:
                grayscale_3ch = torch.cat([grayscale, grayscale, grayscale], dim=1)
            else:
                grayscale_3ch = torch.cat([grayscale, grayscale, grayscale], dim=0)
            
            return grayscale_3ch
        except Exception as e:
            print(f"‚ö†Ô∏è  Error conversi√≥n a grises: {e}")
            # Fallback: promedio simple
            if len(image_tensor.shape) == 4:
                gray_simple = torch.mean(image_tensor, dim=1, keepdim=True)
                return torch.cat([gray_simple, gray_simple, gray_simple], dim=1)
            else:
                gray_simple = torch.mean(image_tensor, dim=0, keepdim=True)
                return torch.cat([gray_simple, gray_simple, gray_simple], dim=0)
    
    def calculate_perceptual_index(self, img1_torch, img2_torch):
        """Calcula √≠ndice perceptual usando KimiaNet (convierte de PyTorch a TensorFlow)"""
        if not self.use_kimianet:
            return 0.0
            
        try:
            # Convertir de PyTorch tensor a numpy
            if len(img1_torch.shape) == 4:  # NCHW -> NHWC
                img1_np = img1_torch.permute(0, 2, 3, 1).cpu().numpy()
                img2_np = img2_torch.permute(0, 2, 3, 1).cpu().numpy()
            else:  # CHW -> HWC
                img1_np = img1_torch.permute(1, 2, 0).cpu().numpy()
                img2_np = img2_torch.permute(1, 2, 0).cpu().numpy()
            
            # Convertir a rango [0, 255] para KimiaNet
            img1_tf = tf.convert_to_tensor(img1_np * 255.0, dtype=tf.float32)
            img2_tf = tf.convert_to_tensor(img2_np * 255.0, dtype=tf.float32)
            
            # Agregar dimensi√≥n de batch si no existe
            if len(img1_tf.shape) == 3:
                img1_tf = tf.expand_dims(img1_tf, 0)
            if len(img2_tf.shape) == 3:
                img2_tf = tf.expand_dims(img2_tf, 0)
            
            # Normalizaci√≥n para DenseNet
            img1_norm = (img1_tf - 127.5) / 127.5
            img2_norm = (img2_tf - 127.5) / 127.5
            
            # Extraer caracter√≠sticas
            features1 = self.feature_extractor(img1_norm)
            features2 = self.feature_extractor(img2_norm)
            
            # Distancia L2 entre caracter√≠sticas
            perceptual_distance = tf.reduce_mean(tf.square(features1 - features2))
            
            return float(perceptual_distance.numpy())
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Error calculando √≠ndice perceptual: {e}")
            return 0.0
    
    def calculate_ms_ssim_pytorch(self, img1, img2, max_val=1.0):
        """
        Implementaci√≥n simplificada de MS-SSIM en PyTorch
        """
        try:
            # Agregar dimensi√≥n de batch si no existe
            if len(img1.shape) == 3:
                img1 = img1.unsqueeze(0)
                img2 = img2.unsqueeze(0)
            
            # Para im√°genes peque√±as, usar SSIM regular
            _, _, h, w = img1.shape
            if h < 64 or w < 64:
                # Usar SSIM de utils_image
                img1_np = (img1.squeeze(0).permute(1, 2, 0).cpu().numpy() * 255.0).astype(np.uint8)
                img2_np = (img2.squeeze(0).permute(1, 2, 0).cpu().numpy() * 255.0).astype(np.uint8)
                return util.calculate_ssim(img1_np, img2_np, border=0)
            
            # Implementaci√≥n b√°sica de MS-SSIM con 3 escalas
            scales = 3
            weights = torch.tensor([0.2, 0.3, 0.5]).to(img1.device)
            ms_ssim_val = torch.tensor(1.0).to(img1.device)
            
            for i in range(scales):
                # Calcular SSIM usando utils_image (m√°s confiable)
                img1_np = (img1.squeeze(0).permute(1, 2, 0).cpu().numpy() * 255.0).astype(np.uint8)
                img2_np = (img2.squeeze(0).permute(1, 2, 0).cpu().numpy() * 255.0).astype(np.uint8)
                ssim_val = util.calculate_ssim(img1_np, img2_np, border=0)
                
                ms_ssim_val *= torch.pow(torch.tensor(ssim_val).to(img1.device), weights[i])
                
                if i < scales - 1:
                    # Downsample para la siguiente escala
                    img1 = F.avg_pool2d(img1, kernel_size=2, stride=2)
                    img2 = F.avg_pool2d(img2, kernel_size=2, stride=2)
            
            return float(ms_ssim_val.item())
            
        except Exception as e:
            # Fallback a SSIM regular
            try:
                img1_np = (img1.squeeze(0).permute(1, 2, 0).cpu().numpy() * 255.0).astype(np.uint8)
                img2_np = (img2.squeeze(0).permute(1, 2, 0).cpu().numpy() * 255.0).astype(np.uint8)
                return util.calculate_ssim(img1_np, img2_np, border=0)
            except:
                return 0.0
    
    def calculate_all_metrics(self, generated_torch, hr_torch):
        """
        Calcula todas las m√©tricas de evaluaci√≥n
        
        Args:
            generated_torch: Imagen generada por SwinIR (tensor PyTorch CHW, [0,1])
            hr_torch: Imagen de alta resoluci√≥n (tensor PyTorch CHW, [0,1])
            
        Returns:
            Dict con todas las m√©tricas
        """
        # ASEGURAR QUE AMBOS TENSORES EST√âN EN EL MISMO DISPOSITIVO
        hr_torch = hr_torch.to(self.device)
        generated_torch = generated_torch.to(self.device)
        
        # Asegurar que las im√°genes tengan el mismo tama√±o
        if generated_torch.shape != hr_torch.shape:
            hr_torch = F.interpolate(
                hr_torch.unsqueeze(0), 
                size=generated_torch.shape[-2:], 
                mode='bicubic', 
                align_corners=False
            ).squeeze(0)
        
        # Convertir a numpy para las m√©tricas de utils_image (esperan [0, 255])
        # MOVER A CPU ANTES DE CONVERTIR A NUMPY
        generated_np = (generated_torch.cpu().permute(1, 2, 0).numpy() * 255.0).astype(np.uint8)
        hr_np = (hr_torch.cpu().permute(1, 2, 0).numpy() * 255.0).astype(np.uint8)
        
        # M√©tricas b√°sicas usando utils_image
        psnr = util.calculate_psnr(generated_np, hr_np, border=0)
        ssim = util.calculate_ssim(generated_np, hr_np, border=0)
        
        # MSE en PyTorch (ambos tensores ya est√°n en GPU)
        mse = F.mse_loss(generated_torch, hr_torch).item()
        
        # MS-SSIM
        try:
            ms_ssim = self.calculate_ms_ssim_pytorch(generated_torch, hr_torch, max_val=1.0)
        except Exception as e:
            print(f"   ‚ö†Ô∏è MS-SSIM fall√≥, usando SSIM: {e}")
            ms_ssim = ssim
        
        # √çndice perceptual (opcional)
        perceptual_index = 0.0
        if self.use_kimianet:
            try:
                perceptual_index = self.calculate_perceptual_index(generated_torch, hr_torch)
            except Exception as e:
                print(f"   ‚ö†Ô∏è Error KimiaNet: {e}")
                perceptual_index = 0.0
        
        return {
            'psnr': float(psnr),
            'ssim': float(ssim),
            'ms_ssim': float(ms_ssim),
            'mse': float(mse),
            'perceptual_index': float(perceptual_index)
        }
    
    def evaluate_single_pair(self, lr_path, hr_path):
        """
        Eval√∫a un par de im√°genes LR-HR
        
        Args:
            lr_path: Ruta a imagen de baja resoluci√≥n
            hr_path: Ruta a imagen de alta resoluci√≥n
            
        Returns:
            Dict con m√©tricas en color y blanco y negro, o None si hay error
        """
        try:
            # Cargar im√°genes
            lr_tensor = self.load_image(lr_path)
            hr_tensor = self.load_image(hr_path)
            
            if lr_tensor is None or hr_tensor is None:
                return None
            
            # MOVER hr_tensor AL DISPOSITIVO CORRECTO DESDE EL INICIO
            hr_tensor = hr_tensor.to(self.device)
            
            # Preparar imagen para el modelo optimizado
            lr_batch = lr_tensor.unsqueeze(0).to(self.device)  # Agregar dimensi√≥n de batch
            
            # Generar imagen con modelo optimizado
            with torch.no_grad():
                generated_batch = self.model(lr_batch)
                
            # Quitar batch dimension
            generated = generated_batch.squeeze(0)
            generated = torch.clamp(generated, 0, 1)
            
            # M√©tricas en COLOR
            color_metrics = self.calculate_all_metrics(generated, hr_tensor)
            
            # Convertir a escala de grises
            generated_gray = self.convert_to_grayscale_torch(generated)
            hr_gray = self.convert_to_grayscale_torch(hr_tensor)
            
            # M√©tricas en BLANCO Y NEGRO
            gray_metrics = self.calculate_all_metrics(generated_gray, hr_gray)
            
            return {
                'lr_path': lr_path,
                'hr_path': hr_path,
                'color_metrics': color_metrics,
                'gray_metrics': gray_metrics
            }
            
        except Exception as e:
            print(f"‚ùå Error procesando par {lr_path} - {hr_path}: {e}")
            return None
    
    def evaluate_model(self, image_pairs, output_dir, model_name):
        """
        Eval√∫a el modelo con todos los pares de im√°genes
        
        Args:
            image_pairs: Lista de tuplas (lr_path, hr_path)
            output_dir: Directorio para guardar resultados
            model_name: Nombre del modelo para los archivos de salida
        """
        print(f"\nüöÄ Iniciando evaluaci√≥n del modelo SwinIR optimizado {model_name}")
        print(f"üìä Procesando {len(image_pairs)} pares de im√°genes...")
        
        # Crear directorio de salida
        os.makedirs(output_dir, exist_ok=True)
        
        # Listas para almacenar resultados
        color_results = []
        gray_results = []
        
        # Procesar cada par de im√°genes
        successful_evaluations = 0
        failed_evaluations = 0
        
        for i, (lr_path, hr_path) in enumerate(tqdm(image_pairs, desc="Evaluando im√°genes")):
            result = self.evaluate_single_pair(lr_path, hr_path)
            
            if result is not None:
                # Preparar datos para CSV
                base_data = {
                    'image_index': i + 1,
                    'lr_path': result['lr_path'],
                    'hr_path': result['hr_path'],
                    'lr_filename': os.path.basename(result['lr_path']),
                    'hr_filename': os.path.basename(result['hr_path'])
                }
                
                # Datos para CSV de color
                color_row = base_data.copy()
                color_row.update(result['color_metrics'])
                color_results.append(color_row)
                
                # Datos para CSV de escala de grises
                gray_row = base_data.copy()
                gray_row.update(result['gray_metrics'])
                gray_results.append(gray_row)
                
                successful_evaluations += 1
            else:
                failed_evaluations += 1
        
        print(f"\nüìà Evaluaci√≥n completada:")
        print(f"   ‚úÖ Exitosas: {successful_evaluations}")
        print(f"   ‚ùå Fallidas: {failed_evaluations}")
        
        # Crear DataFrames y guardar CSVs
        if color_results:
            # CSV para m√©tricas en color
            color_df = pd.DataFrame(color_results)
            color_csv_path = os.path.join(output_dir, f"{model_name}_metrics_color.csv")
            color_df.to_csv(color_csv_path, index=False)
            print(f"üíæ M√©tricas en COLOR guardadas: {color_csv_path}")
            
            # CSV para m√©tricas en escala de grises
            gray_df = pd.DataFrame(gray_results)
            gray_csv_path = os.path.join(output_dir, f"{model_name}_metrics_grayscale.csv")
            gray_df.to_csv(gray_csv_path, index=False)
            print(f"üíæ M√©tricas en ESCALA DE GRISES guardadas: {gray_csv_path}")
            
            # Mostrar estad√≠sticas resumidas
            self._print_summary_statistics(color_df, gray_df, model_name)
            
        else:
            print("‚ùå No se pudieron evaluar im√°genes correctamente")
    
    def _print_summary_statistics(self, color_df, gray_df, model_name):
        """Imprime estad√≠sticas resumidas"""
        print(f"\nüìä ESTAD√çSTICAS RESUMIDAS - {model_name}")
        print("=" * 50)
        
        metrics = ['psnr', 'ssim', 'ms_ssim', 'mse', 'perceptual_index']
        
        print("COLOR:")
        for metric in metrics:
            if metric in color_df.columns:
                mean_val = color_df[metric].mean()
                std_val = color_df[metric].std()
                if metric == 'perceptual_index' and mean_val == 0.0:
                    print(f"  {metric.upper()}: N/A (KimiaNet deshabilitado)")
                else:
                    print(f"  {metric.upper()}: {mean_val:.6f} ¬± {std_val:.6f}")
        
        print("\nESCALA DE GRISES:")
        for metric in metrics:
            if metric in gray_df.columns:
                mean_val = gray_df[metric].mean()
                std_val = gray_df[metric].std()
                if metric == 'perceptual_index' and mean_val == 0.0:
                    print(f"  {metric.upper()}: N/A (KimiaNet deshabilitado)")
                else:
                    print(f"  {metric.upper()}: {mean_val:.6f} ¬± {std_val:.6f}")

def main():
    """Funci√≥n principal"""
    parser = argparse.ArgumentParser(description="Evaluador de Validaci√≥n para Modelo SwinIR Optimizado")
    
    parser.add_argument(
        "--model_path",
        required=True,
        help="Ruta al modelo SwinIR optimizado (.pt file)"
    )
    
    parser.add_argument(
        "--model_name", 
        required=True,
        help="Nombre del modelo (ej: SwinIR_128to256_optimized)"
    )
    
    parser.add_argument(
        "--lr_meta_file",
        required=True,
        help="Archivo meta con rutas de im√°genes LR (ej: paired_lr_meta.txt)"
    )
    
    parser.add_argument(
        "--hr_meta_file",
        required=True,
        help="Archivo meta con rutas de im√°genes HR (ej: paired_hr_meta.txt)"
    )
    
    parser.add_argument(
        "--kimianet_weights",
        default=None,
        help="Ruta a los pesos de KimiaNet (opcional - si no se proporciona, se deshabilita)"
    )
    
    parser.add_argument(
        "--use_kimianet",
        action='store_true',
        help="Usar KimiaNet para √≠ndice perceptual (requiere --kimianet_weights)"
    )
    
    parser.add_argument(
        "--base_path",
        default="",
        help="Ruta base para las im√°genes (si las rutas en meta_info son relativas)"
    )
    
    parser.add_argument(
        "--output_dir",
        default="./evaluation_results",
        help="Directorio para guardar los resultados CSV"
    )
    
    parser.add_argument(
        "--max_images",
        type=int,
        default=None,
        help="M√°ximo n√∫mero de im√°genes a evaluar (para pruebas r√°pidas)"
    )
    
    args = parser.parse_args()
    
    # Verificar que los archivos existen
    required_files = [args.model_path, args.lr_meta_file, args.hr_meta_file]
    for file_path in required_files:
        if not os.path.exists(file_path):
            print(f"‚ùå Error: No se encuentra el archivo/directorio: {file_path}")
            return 1
    
    # Configurar KimiaNet
    use_kimianet = args.use_kimianet and args.kimianet_weights is not None
    if args.use_kimianet and args.kimianet_weights is None:
        print("‚ö†Ô∏è  --use_kimianet especificado pero no --kimianet_weights. KimiaNet deshabilitado.")
        use_kimianet = False
    
    print("üî¨ EVALUADOR DE MODELO SWINIR OPTIMIZADO")
    print("=" * 40)
    print(f"Modelo: {args.model_name}")
    print(f"Ruta del modelo: {args.model_path}")
    print(f"Dataset LR: {args.lr_meta_file}")
    print(f"Dataset HR: {args.hr_meta_file}")
    print(f"KimiaNet: {'Habilitado' if use_kimianet else 'Deshabilitado'}")
    if use_kimianet:
        print(f"KimiaNet pesos: {args.kimianet_weights}")
    print(f"Resultados: {args.output_dir}")
    
    try:
        # Inicializar evaluador
        evaluator = OptimizedSwinIRModelEvaluator(
            use_kimianet=use_kimianet,
            kimianet_weights_path=args.kimianet_weights
        )
        
        # Cargar modelo optimizado
        evaluator.load_optimized_model(args.model_path)
        
        # Cargar dataset de validaci√≥n
        image_pairs = evaluator.load_validation_dataset(
            args.lr_meta_file, args.hr_meta_file, args.base_path
        )
        
        # Limitar n√∫mero de im√°genes si se especifica
        if args.max_images and args.max_images < len(image_pairs):
            image_pairs = image_pairs[:args.max_images]
            print(f"üî¢ Limitando evaluaci√≥n a {args.max_images} im√°genes")
        
        # Evaluar modelo
        evaluator.evaluate_model(image_pairs, args.output_dir, args.model_name)
        
        print(f"\nüéâ Evaluaci√≥n completada exitosamente!")
        print(f"üìÇ Archivos CSV generados en: {args.output_dir}")
        
        return 0
        
    except Exception as e:
        print(f"\nüí• Error fatal durante la evaluaci√≥n: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit(main())